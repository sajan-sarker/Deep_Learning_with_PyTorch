{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUwqWgj5jA/hWLEtU4Ot/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajan-sarker/PyTorch_Practice_Codes/blob/main/PyTorch_Practice_NN_Heart_Disease_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Practice Code"
      ],
      "metadata": {
        "id": "w18x6kyonQCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ryustgzk_DD",
        "outputId": "0bea27d3-3a21-46af-ffa8-0e09c3dcf0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "KSbIZadBOzrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Dataset"
      ],
      "metadata": {
        "id": "cvywTP1RPaq-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRI1_7FYOgyd",
        "outputId": "57e6ef9a-22e1-4d33-a6ba-dcfa02cd735f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"oktayrdeki/heart-disease\")\n",
        "\n",
        "#print(\"Path to dataset files:\", path)\n",
        "df = pd.read_csv(path+'/heart_disease.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4GVmtbXiSRft",
        "outputId": "f7aac58c-40b5-4c3f-cc91-b6b28cba0aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Age                   9971 non-null   float64\n",
            " 1   Gender                9981 non-null   object \n",
            " 2   Blood Pressure        9981 non-null   float64\n",
            " 3   Cholesterol Level     9970 non-null   float64\n",
            " 4   Exercise Habits       9975 non-null   object \n",
            " 5   Smoking               9975 non-null   object \n",
            " 6   Family Heart Disease  9979 non-null   object \n",
            " 7   Diabetes              9970 non-null   object \n",
            " 8   BMI                   9978 non-null   float64\n",
            " 9   High Blood Pressure   9974 non-null   object \n",
            " 10  Low HDL Cholesterol   9975 non-null   object \n",
            " 11  High LDL Cholesterol  9974 non-null   object \n",
            " 12  Alcohol Consumption   7414 non-null   object \n",
            " 13  Stress Level          9978 non-null   object \n",
            " 14  Sleep Hours           9975 non-null   float64\n",
            " 15  Sugar Consumption     9970 non-null   object \n",
            " 16  Triglyceride Level    9974 non-null   float64\n",
            " 17  Fasting Blood Sugar   9978 non-null   float64\n",
            " 18  CRP Level             9974 non-null   float64\n",
            " 19  Homocysteine Level    9980 non-null   float64\n",
            " 20  Heart Disease Status  10000 non-null  object \n",
            "dtypes: float64(9), object(12)\n",
            "memory usage: 1.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0ysDlYyCUVed",
        "outputId": "4edbcafb-62cc-4eaa-8c2f-450591dccd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age                       29\n",
            "Gender                    19\n",
            "Blood Pressure            19\n",
            "Cholesterol Level         30\n",
            "Exercise Habits           25\n",
            "Smoking                   25\n",
            "Family Heart Disease      21\n",
            "Diabetes                  30\n",
            "BMI                       22\n",
            "High Blood Pressure       26\n",
            "Low HDL Cholesterol       25\n",
            "High LDL Cholesterol      26\n",
            "Alcohol Consumption     2586\n",
            "Stress Level              22\n",
            "Sleep Hours               25\n",
            "Sugar Consumption         30\n",
            "Triglyceride Level        26\n",
            "Fasting Blood Sugar       22\n",
            "CRP Level                 26\n",
            "Homocysteine Level        20\n",
            "Heart Disease Status       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "kqNVVV_rePLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include='float64')\n",
        "df[num_cols.columns]=num_cols.fillna(num_cols.mean()) # filling the missing values with the mean of the features\n",
        "df = df.drop(columns='Alcohol Consumption', axis=1)"
      ],
      "metadata": {
        "id": "XT3kA_bxUF6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_cols = df.select_dtypes(include='object')\n",
        "for col in obj_cols.columns:\n",
        "  most_freq = df[col].mode()\n",
        "  if not most_freq.empty:\n",
        "    df[col].fillna(most_freq[0], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sfmm3_UWVxTl",
        "outputId": "60db854e-e07b-497c-cb31-7b196f90a603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-0d73ad6d9167>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(most_freq[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Heart Disease Status']\n",
        "X = df.drop(columns='Heart Disease Status', axis=1)\n",
        "\n",
        "label_encoder_features = LabelEncoder()\n",
        "label_encoder_target = LabelEncoder()\n",
        "\n",
        "cat_cols = X.select_dtypes(include='object').columns\n",
        "# encode categorical features\n",
        "for col in X[cat_cols]:\n",
        "  X[col] = label_encoder_features.fit_transform(X[col])\n",
        "y = label_encoder_target.fit_transform(y)"
      ],
      "metadata": {
        "id": "U42-Lf5TY372"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "7Gh5cUm4Xd_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neunal Network Model Building"
      ],
      "metadata": {
        "id": "GeA-T4xzeTUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        # first hidden layer\n",
        "        nn.Linear(input_size, 5),\n",
        "        nn.ReLU(),\n",
        "        # second hidden layer\n",
        "        nn.Linear(5, 3),\n",
        "        nn.ReLU(),\n",
        "        # third hidden layer\n",
        "        nn.Linear(3, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, features):\n",
        "    out = self.network(features)\n",
        "    return out"
      ],
      "metadata": {
        "id": "oagzhbe_eVcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train(X_train, y_train, X_val, y_val, input_size, batch_size, learning_rate, num_epochs):\n",
        "  # convert data into Tensors\n",
        "  X_train = torch.FloatTensor(X_train)\n",
        "  y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
        "  X_val = torch.FloatTensor(X_val)\n",
        "  y_val = torch.FloatTensor(y_val).unsqueeze(1)\n",
        "\n",
        "  # create dataloader for training set\n",
        "  train_dataset = TensorDataset(X_train, y_train)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  # initialize model, loss funciton and optimizer\n",
        "  device = torch.device('cude' if torch.cuda.is_available() else 'cpu')\n",
        "  model = NN(input_size).to(device)\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "\n",
        "  # training loop\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    running_train_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "      batch_X = batch_X.to(device)\n",
        "      batch_y = batch_y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(batch_X)\n",
        "      train_loss = criterion(outputs, batch_y)\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "      running_train_loss += train_loss.item()\n",
        "\n",
        "    # calculate average training loss\n",
        "    avg_train_loss = running_train_loss/len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # validation phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      X_val = X_val.to(device)\n",
        "      y_val = y_val.to(device)\n",
        "      val_outputs = model(X_val)\n",
        "      val_loss = criterion(val_outputs, y_val)\n",
        "      val_losses.append(val_loss.item())\n",
        "      val_predictions = (val_outputs >= 0.5).float()\n",
        "      val_accuracy = (val_predictions.eq(y_val).sum() / float(y_val.shape[0])).item()\n",
        "    model.train()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "  return model, train_losses, val_losses"
      ],
      "metadata": {
        "id": "5dk-YpNJfRO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(X_train.shape[1])\n",
        "summary(model, input_size=(X_train.shape[1],))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2OMK_ailJbB",
        "outputId": "ba156486-e2f9-4686-cd69-b9de78f5a30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "NN                                       [1]                       --\n",
              "├─Sequential: 1-1                        [1]                       --\n",
              "│    └─Linear: 2-1                       [5]                       100\n",
              "│    └─ReLU: 2-2                         [5]                       --\n",
              "│    └─Linear: 2-3                       [3]                       18\n",
              "│    └─ReLU: 2-4                         [3]                       --\n",
              "│    └─Linear: 2-5                       [1]                       4\n",
              "│    └─Sigmoid: 2-6                      [1]                       --\n",
              "==========================================================================================\n",
              "Total params: 122\n",
              "Trainable params: 122\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model, train_loss, val_loss = model_train(X_train, y_train, X_val, y_val, X_train.shape[1], 32, 0.01, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOlHtsLFjwmA",
        "outputId": "19467bb2-4289-4a28-b287-08549c219381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Loss: 0.5138, Val Loss: 0.4891, Val Accuracy: 0.8080\n",
            "Epoch [2/50], Train Loss: 0.5028, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [3/50], Train Loss: 0.5027, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [4/50], Train Loss: 0.5027, Val Loss: 0.4891, Val Accuracy: 0.8080\n",
            "Epoch [5/50], Train Loss: 0.5030, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [6/50], Train Loss: 0.5030, Val Loss: 0.4893, Val Accuracy: 0.8080\n",
            "Epoch [7/50], Train Loss: 0.5029, Val Loss: 0.4893, Val Accuracy: 0.8080\n",
            "Epoch [8/50], Train Loss: 0.5026, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [9/50], Train Loss: 0.5029, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [10/50], Train Loss: 0.5030, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [11/50], Train Loss: 0.5028, Val Loss: 0.4891, Val Accuracy: 0.8080\n",
            "Epoch [12/50], Train Loss: 0.5029, Val Loss: 0.4894, Val Accuracy: 0.8080\n",
            "Epoch [13/50], Train Loss: 0.5027, Val Loss: 0.4903, Val Accuracy: 0.8080\n",
            "Epoch [14/50], Train Loss: 0.5025, Val Loss: 0.4891, Val Accuracy: 0.8080\n",
            "Epoch [15/50], Train Loss: 0.5027, Val Loss: 0.4896, Val Accuracy: 0.8080\n",
            "Epoch [16/50], Train Loss: 0.5026, Val Loss: 0.4891, Val Accuracy: 0.8080\n",
            "Epoch [17/50], Train Loss: 0.5031, Val Loss: 0.4897, Val Accuracy: 0.8080\n",
            "Epoch [18/50], Train Loss: 0.5029, Val Loss: 0.4891, Val Accuracy: 0.8080\n",
            "Epoch [19/50], Train Loss: 0.5028, Val Loss: 0.4895, Val Accuracy: 0.8080\n",
            "Epoch [20/50], Train Loss: 0.5026, Val Loss: 0.4896, Val Accuracy: 0.8080\n",
            "Epoch [21/50], Train Loss: 0.5030, Val Loss: 0.4893, Val Accuracy: 0.8080\n",
            "Epoch [22/50], Train Loss: 0.5028, Val Loss: 0.4896, Val Accuracy: 0.8080\n",
            "Epoch [23/50], Train Loss: 0.5030, Val Loss: 0.4891, Val Accuracy: 0.8080\n",
            "Epoch [24/50], Train Loss: 0.5029, Val Loss: 0.4896, Val Accuracy: 0.8080\n",
            "Epoch [25/50], Train Loss: 0.5030, Val Loss: 0.4900, Val Accuracy: 0.8080\n",
            "Epoch [26/50], Train Loss: 0.5030, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [27/50], Train Loss: 0.5026, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [28/50], Train Loss: 0.5029, Val Loss: 0.4894, Val Accuracy: 0.8080\n",
            "Epoch [29/50], Train Loss: 0.5028, Val Loss: 0.4893, Val Accuracy: 0.8080\n",
            "Epoch [30/50], Train Loss: 0.5025, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [31/50], Train Loss: 0.5027, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [32/50], Train Loss: 0.5027, Val Loss: 0.4899, Val Accuracy: 0.8080\n",
            "Epoch [33/50], Train Loss: 0.5027, Val Loss: 0.4895, Val Accuracy: 0.8080\n",
            "Epoch [34/50], Train Loss: 0.5028, Val Loss: 0.4900, Val Accuracy: 0.8080\n",
            "Epoch [35/50], Train Loss: 0.5026, Val Loss: 0.4891, Val Accuracy: 0.8080\n",
            "Epoch [36/50], Train Loss: 0.5027, Val Loss: 0.4894, Val Accuracy: 0.8080\n",
            "Epoch [37/50], Train Loss: 0.5028, Val Loss: 0.4897, Val Accuracy: 0.8080\n",
            "Epoch [38/50], Train Loss: 0.5028, Val Loss: 0.4894, Val Accuracy: 0.8080\n",
            "Epoch [39/50], Train Loss: 0.5029, Val Loss: 0.4894, Val Accuracy: 0.8080\n",
            "Epoch [40/50], Train Loss: 0.5027, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [41/50], Train Loss: 0.5028, Val Loss: 0.4896, Val Accuracy: 0.8080\n",
            "Epoch [42/50], Train Loss: 0.5029, Val Loss: 0.4895, Val Accuracy: 0.8080\n",
            "Epoch [43/50], Train Loss: 0.5029, Val Loss: 0.4897, Val Accuracy: 0.8080\n",
            "Epoch [44/50], Train Loss: 0.5030, Val Loss: 0.4897, Val Accuracy: 0.8080\n",
            "Epoch [45/50], Train Loss: 0.5030, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [46/50], Train Loss: 0.5029, Val Loss: 0.4892, Val Accuracy: 0.8080\n",
            "Epoch [47/50], Train Loss: 0.5029, Val Loss: 0.4895, Val Accuracy: 0.8080\n",
            "Epoch [48/50], Train Loss: 0.5029, Val Loss: 0.4902, Val Accuracy: 0.8080\n",
            "Epoch [49/50], Train Loss: 0.5030, Val Loss: 0.4893, Val Accuracy: 0.8080\n",
            "Epoch [50/50], Train Loss: 0.5029, Val Loss: 0.4898, Val Accuracy: 0.8080\n",
            "CPU times: user 21.3 s, sys: 30.7 ms, total: 21.3 s\n",
            "Wall time: 21.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = list(model.parameters())\n",
        "\n",
        "for i, param in enumerate(model.parameters()):\n",
        "    print(f\"Parameter {i}: shape = {param.shape}\")\n",
        "    # print(param)  # Uncomment to see the actual tensor values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSF0M9W0j985",
        "outputId": "bf75b692-a506-438b-ebfc-514255996545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter 0: shape = torch.Size([5, 19])\n",
            "Parameter 1: shape = torch.Size([5])\n",
            "Parameter 2: shape = torch.Size([3, 5])\n",
            "Parameter 3: shape = torch.Size([3])\n",
            "Parameter 4: shape = torch.Size([1, 3])\n",
            "Parameter 5: shape = torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'model' is your trained NN instance\n",
        "# Get weights and biases for each Linear layer in the network\n",
        "\n",
        "# First hidden layer (num_features -> 5)\n",
        "weight1 = model.network[0].weight.data  # Shape: (5, num_features)\n",
        "bias1 = model.network[0].bias.data      # Shape: (5,)\n",
        "\n",
        "# Second hidden layer (5 -> 3)\n",
        "weight2 = model.network[2].weight.data  # Shape: (3, 5)\n",
        "bias2 = model.network[2].bias.data      # Shape: (3,)\n",
        "\n",
        "# Third hidden layer (3 -> 1)\n",
        "weight3 = model.network[4].weight.data  # Shape: (1, 3)\n",
        "bias3 = model.network[4].bias.data      # Shape: (1,)\n",
        "\n",
        "# Optional: Print them to verify\n",
        "print(\"First Layer Weights:\\n\", weight1)\n",
        "print(\"First Layer Biases:\\n\", bias1)\n",
        "print(\"Second Layer Weights:\\n\", weight2)\n",
        "print(\"Second Layer Biases:\\n\", bias2)\n",
        "print(\"Third Layer Weights:\\n\", weight3)\n",
        "print(\"Third Layer Biases:\\n\", bias3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJBYfPbelScQ",
        "outputId": "333ee257-f2c2-48d9-8b7e-cc67acd29cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Layer Weights:\n",
            " tensor([[ 2.8269e-02,  1.2095e-01,  2.2711e-01,  1.7547e-01,  2.7030e-02,\n",
            "          3.5280e-02, -1.7148e-01,  2.4663e-01, -2.2709e-01, -2.1423e-01,\n",
            "          9.3512e-02,  2.0054e-01,  1.0654e-01, -1.4674e-02, -1.0468e-01,\n",
            "          2.0094e-02,  1.9525e-02,  3.3871e-02, -2.5295e-01],\n",
            "        [-7.1505e-02, -3.0973e-01, -1.2926e-01, -2.9150e-01,  1.5016e-01,\n",
            "          1.2252e-02,  1.3324e-01,  2.7900e-01, -1.7190e-01, -1.8996e-02,\n",
            "         -2.2946e-01,  3.0023e-01, -2.8385e-01,  2.3134e-01, -5.9619e-02,\n",
            "          4.8256e-02, -8.9575e-02, -1.5250e-01,  5.8856e-02],\n",
            "        [-2.1486e-01,  3.1651e-02,  4.2000e-02,  5.2087e-02,  2.5094e-01,\n",
            "          2.0579e-02, -6.7470e-02,  1.7323e-01,  9.2217e-02, -4.9068e-02,\n",
            "          1.5926e-01,  1.2028e-01, -7.0278e-02,  1.6187e-01,  1.1167e-01,\n",
            "          2.7400e-01, -1.0934e-01, -1.0872e-01,  2.7178e-01],\n",
            "        [-8.5326e-02, -1.4658e-01,  2.2368e-01, -3.5930e-03,  3.0699e-02,\n",
            "          1.5045e-01,  6.8869e-02,  2.8594e-01,  1.9290e-01,  1.2321e-01,\n",
            "         -1.5977e-01, -4.9377e-02,  1.1047e-01,  2.7884e-01, -2.0255e-01,\n",
            "         -1.5701e-01,  1.2072e-01, -6.8661e-02, -2.6089e-01],\n",
            "        [ 8.6348e-02,  2.0903e-02,  5.8172e-02, -6.5551e-02,  2.7638e-04,\n",
            "          6.7153e-02, -3.8095e-03,  5.1004e-02, -5.3734e-02, -2.1735e-02,\n",
            "          1.2772e-01,  9.5711e-03, -6.5769e-02,  8.2744e-02, -7.8031e-02,\n",
            "          9.9970e-02, -1.6483e-01, -7.2733e-02,  9.6071e-03]])\n",
            "First Layer Biases:\n",
            " tensor([ 0.0298, -0.1227,  0.0512, -0.0911, -0.2901])\n",
            "Second Layer Weights:\n",
            " tensor([[-0.1534, -0.4204, -0.4439, -0.1115,  0.2557],\n",
            "        [-0.2894, -0.2226,  0.1151, -0.2082, -0.0926],\n",
            "        [-0.2815, -0.1532, -0.2658, -0.2844,  0.2888]])\n",
            "Second Layer Biases:\n",
            " tensor([-0.1852, -0.3871, -0.1395])\n",
            "Third Layer Weights:\n",
            " tensor([[0.3954, 0.4902, 0.1332]])\n",
            "Third Layer Biases:\n",
            " tensor([-1.3447])\n"
          ]
        }
      ]
    }
  ]
}